{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e25562d03a5345c8883776acc3242aa6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2b185a36f254a1dbfd8723c96cd5d84","IPY_MODEL_f3ad65eeb8f64a7bad6e4f8b21e34d46","IPY_MODEL_3e7f6f57a40841ed9049a322179055e2"],"layout":"IPY_MODEL_69f479beee014b258d0c5f2abaa6d559"}},"c2b185a36f254a1dbfd8723c96cd5d84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d98f9e411d04846b15e260c2a3b04ab","placeholder":"​","style":"IPY_MODEL_d6cbfa7f55ae453087f888101cfac940","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"f3ad65eeb8f64a7bad6e4f8b21e34d46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba7ea2d64c65475a939a60dbb895b79b","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b574ac044e6488a8b7501cec58882ea","value":231508}},"3e7f6f57a40841ed9049a322179055e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f57bfd085ac14b37872747e33b0df5cd","placeholder":"​","style":"IPY_MODEL_8e2649de05e14951a6539954abb4b2c0","value":" 232k/232k [00:00&lt;00:00, 3.09MB/s]"}},"69f479beee014b258d0c5f2abaa6d559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d98f9e411d04846b15e260c2a3b04ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6cbfa7f55ae453087f888101cfac940":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba7ea2d64c65475a939a60dbb895b79b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b574ac044e6488a8b7501cec58882ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f57bfd085ac14b37872747e33b0df5cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e2649de05e14951a6539954abb4b2c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71e007137c1d47ac90ec89ab01204b45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4a889e110a6491c8a48b7e2ae9266f6","IPY_MODEL_71d034de7baf49119ce0c17d2dc3171f","IPY_MODEL_f2f397cf81e443839cf3ff23f33cdb7e"],"layout":"IPY_MODEL_b34a6402b283464c9a1bb697cc108db4"}},"e4a889e110a6491c8a48b7e2ae9266f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2b1adb0bdf349efaa799f8730a30b07","placeholder":"​","style":"IPY_MODEL_8bac3db7a5ff4e3b94017bc402162b0b","value":"Downloading (…)okenizer_config.json: 100%"}},"71d034de7baf49119ce0c17d2dc3171f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cc03c8fdac043a08cea7b1c8f3fe36e","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c74c91e49f64ba39097bbbd4402626a","value":28}},"f2f397cf81e443839cf3ff23f33cdb7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98a56241dc6b4be5b329bab594bb4c05","placeholder":"​","style":"IPY_MODEL_232555988dba49a0b0b702a7a3fbfa0e","value":" 28.0/28.0 [00:00&lt;00:00, 430B/s]"}},"b34a6402b283464c9a1bb697cc108db4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2b1adb0bdf349efaa799f8730a30b07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bac3db7a5ff4e3b94017bc402162b0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cc03c8fdac043a08cea7b1c8f3fe36e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c74c91e49f64ba39097bbbd4402626a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98a56241dc6b4be5b329bab594bb4c05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"232555988dba49a0b0b702a7a3fbfa0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b508f3e0a4984eabaa5ce842780db8b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec5d0ec1fdc84096bc1d2a5a0650eed8","IPY_MODEL_3c56a77571d14d2496a1372869f3454d","IPY_MODEL_2941e2c504de49ac9b0d310e3f3eac15"],"layout":"IPY_MODEL_88af7c96a17c4447995dd13497641ffc"}},"ec5d0ec1fdc84096bc1d2a5a0650eed8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dcb18f6b0f54b7e8db3618e9c78b8b8","placeholder":"​","style":"IPY_MODEL_2aaf62a0c0e6401da6780d90952894e4","value":"Downloading (…)lve/main/config.json: 100%"}},"3c56a77571d14d2496a1372869f3454d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_472607207fba404b8587202aa0f46d8b","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b0cc35a13da4253a0efcc5d280dedfb","value":483}},"2941e2c504de49ac9b0d310e3f3eac15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68d02eb8cb534ceead54d30f3190db94","placeholder":"​","style":"IPY_MODEL_eef761cf4f1f495d8e17cfee8ad8ab20","value":" 483/483 [00:00&lt;00:00, 21.5kB/s]"}},"88af7c96a17c4447995dd13497641ffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dcb18f6b0f54b7e8db3618e9c78b8b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aaf62a0c0e6401da6780d90952894e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"472607207fba404b8587202aa0f46d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b0cc35a13da4253a0efcc5d280dedfb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68d02eb8cb534ceead54d30f3190db94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef761cf4f1f495d8e17cfee8ad8ab20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1738fdd64304495caf6080f9f1944a34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99fe98ba8a664c5498f05e25dd91a63d","IPY_MODEL_973169ecec7c42089dd34c4a1d765ee6","IPY_MODEL_4fa9e498da364ef28c58bb3920a4bde8"],"layout":"IPY_MODEL_6c45bd0d45024ec2a70b5ffb0b0c5bc4"}},"99fe98ba8a664c5498f05e25dd91a63d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9dcd293c1f7426392d3f3e2783ad702","placeholder":"​","style":"IPY_MODEL_b7db8c296ebb4d159c65c13808fe0642","value":"Downloading model.safetensors: 100%"}},"973169ecec7c42089dd34c4a1d765ee6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1daad78e0b614a309060ea63c500f09f","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b73619801fe449785becd40a7db2b51","value":267954768}},"4fa9e498da364ef28c58bb3920a4bde8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d2dd4fc11a84c009c8327fbe1dc47ef","placeholder":"​","style":"IPY_MODEL_9e763dce91d6464e9db9e556aad5632b","value":" 268M/268M [00:00&lt;00:00, 341MB/s]"}},"6c45bd0d45024ec2a70b5ffb0b0c5bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9dcd293c1f7426392d3f3e2783ad702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7db8c296ebb4d159c65c13808fe0642":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1daad78e0b614a309060ea63c500f09f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b73619801fe449785becd40a7db2b51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d2dd4fc11a84c009c8327fbe1dc47ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e763dce91d6464e9db9e556aad5632b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"o17F95XwDImo"},"source":["# Automated Essay Scoring\n","\n","### What is this Notebook about?\n","\n","- This Notebook contains all raw results and experiments done with the various deep learning methods. The output cells contains the results that we got. The whole Notebook may take approximately 5-6 hours. This Notebook contains the following:\n","\n","* Preprocess data\n","* Important util methods to be used later\n","* Deep Learning Model declaration\n","* Running bert for individual sets\n","* Running bert for whole dataset\n","* Running word2vec for individual sets\n","* Running word2vec for whole dataset"]},{"cell_type":"code","metadata":{"id":"0B76LD1O7uP1","outputId":"d382d322-7fd8-4b17-a3f7-b7542708e74f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691975177313,"user_tz":240,"elapsed":34411,"user":{"displayName":"Daniel Lee","userId":"12738379721108466912"}}},"source":["# import important libraries and download data\n","import os\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import re\n","from nltk.corpus import stopwords\n","from gensim.models import Word2Vec\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import cohen_kappa_score\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","import multiprocessing\n","%matplotlib notebook\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","! git clone https://github.com/Gaurav-Pande/AES_DL.git && mv AES_DL/data .\n","! pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Cloning into 'AES_DL'...\n","remote: Enumerating objects: 62, done.\u001b[K\n","remote: Counting objects: 100% (62/62), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 62 (delta 27), reused 28 (delta 8), pack-reused 0\u001b[K\n","Receiving objects: 100% (62/62), 6.38 MiB | 13.17 MiB/s, done.\n","Resolving deltas: 100% (27/27), done.\n","Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"]}]},{"cell_type":"code","metadata":{"id":"UDmr9sRxmWeW"},"source":["# Declaring some visualization methods to plot accuracy and model diagram\n","def plot_accuracy_curve(history):\n","  import matplotlib.pyplot as plt\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['mae'])\n","  plt.title('Model loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Test'], loc='upper left')\n","  plt.show()\n","\n","def plot_acrchitecture(filename, model):\n","  from keras.utils import plot_model\n","  plot_model(model, to_file=str(filename) + '.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnA5ciNY8Fhj"},"source":["# method to split data into sets\n","def split_in_sets(data):\n","    essay_sets = []\n","    min_scores = []\n","    max_scores = []\n","    for s in range(1,9):\n","        essay_set = data[data[\"essay_set\"] == s]\n","        essay_set.dropna(axis=1, inplace=True)\n","        n, d = essay_set.shape\n","        set_scores = essay_set[\"domain1_score\"]\n","        print (\"Set\", s, \": Essays = \", n , \"\\t Attributes = \", d)\n","        min_scores.append(set_scores.min())\n","        max_scores.append(set_scores.max())\n","        essay_sets.append(essay_set)\n","    return (essay_sets, min_scores, max_scores)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_yJZ-g5GVQd"},"source":["In the below cell, we can see the data we need to operate. We essentially drops the column, we dont need and keep the domain_score only along with essay text."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_n9LO58pqvV","executionInfo":{"status":"ok","timestamp":1691909310789,"user_tz":240,"elapsed":18118,"user":{"displayName":"Jun Seob Shim","userId":"14058722238538116434"}},"outputId":"802c41e3-e396-415b-a246-c37c4b917801"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"8CwSNzeK8J38","outputId":"f46c6e6c-ab85-4d62-fea0-359ed5cd05c4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1691909323103,"user_tz":240,"elapsed":2500,"user":{"displayName":"Jun Seob Shim","userId":"14058722238538116434"}}},"source":["dataset_path = \"/content/drive/MyDrive/DS 301 Project AES/Dataset/training_set_rel3.tsv\"\n","data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\")\n","min_scores = [2, 1, 0, 0, 0, 0, 0, 0]\n","max_scores = [12, 6, 3, 3, 4, 4, 30, 60]\n","essay_sets, data_min_scores, data_max_scores = split_in_sets(data)\n","set1, set2, set3, set4, set5, set6, set7, set8 = tuple(essay_sets)\n","data.dropna(axis=1, inplace=True)\n","data.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set1.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set2.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set3.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set4.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set5.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set6.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set7.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","set8.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","sets = [set1,set2,set3,set4,set5,set6,set7,set8]\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Set 1 : Essays =  1783 \t Attributes =  6\n","Set 2 : Essays =  1800 \t Attributes =  9\n","Set 3 : Essays =  1726 \t Attributes =  6\n","Set 4 : Essays =  1770 \t Attributes =  6\n","Set 5 : Essays =  1805 \t Attributes =  6\n","Set 6 : Essays =  1800 \t Attributes =  6\n","Set 7 : Essays =  1569 \t Attributes =  14\n","Set 8 : Essays =  723 \t Attributes =  18\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-3-069322bfa85e>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  essay_set.dropna(axis=1, inplace=True)\n","<ipython-input-5-5711edd1f3d5>:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set1.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set2.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set3.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set4.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set5.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set6.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set7.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n","<ipython-input-5-5711edd1f3d5>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  set8.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["   essay_id  essay_set                                              essay  \\\n","0         1          1  Dear local newspaper, I think effects computer...   \n","1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n","2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n","3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n","4         5          1  Dear @LOCATION1, I know having computers has a...   \n","\n","   domain1_score  \n","0              8  \n","1              9  \n","2              7  \n","3             10  \n","4              8  "],"text/html":["\n","\n","  <div id=\"df-3343ed6e-a5c1-4c14-802e-ac2a4e9862a5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>essay_id</th>\n","      <th>essay_set</th>\n","      <th>essay</th>\n","      <th>domain1_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Dear local newspaper, I think effects computer...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>Dear @LOCATION1, I know having computers has a...</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3343ed6e-a5c1-4c14-802e-ac2a4e9862a5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-82129905-525c-48fb-9a8e-e426d12d709b\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82129905-525c-48fb-9a8e-e426d12d709b')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-82129905-525c-48fb-9a8e-e426d12d709b button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3343ed6e-a5c1-4c14-802e-ac2a4e9862a5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3343ed6e-a5c1-4c14-802e-ac2a4e9862a5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"lrhajVfgGmzi"},"source":[" There are named entity tags as you can see above, which can impact our model. so we need to remove them from the dataframe. So we will extend our stopwords set later on. But first we need to create all possible ner tags."]},{"cell_type":"code","metadata":{"id":"SRZkhVx5txSk"},"source":["cap = ['@CAPS'+str(i) for i in range(100)]\n","loc = ['@LOCATION'+str(i) for i in range(100)]\n","org =['@ORGANIZATION'+str(i) for i in range(100)]\n","per = ['@PERSON'+str(i) for i in range(100)]\n","date = ['@DATE'+str(i) for i in range(100)]\n","time = ['@TIME'+str(i) for i in range(100)]\n","money = ['@MONEY'+str(i) for i in range(100)]\n","ner =  cap + loc + org + per + date + time + money"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xDf0xcDbG3Cd"},"source":["Some utility functions declarations needed to convert the raw essay to word list."]},{"cell_type":"code","metadata":{"id":"JZs2tjKT8Szi"},"source":["import collections\n","top10 = collections.defaultdict(int)\n","def essay_to_wordlist(essay_v, remove_stopwords):\n","    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n","    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n","    words = essay_v.lower().split()\n","    #top10 = collections.defaultdict(int)\n","    if remove_stopwords:\n","        stops = stopwords.words(\"english\")\n","        stops.extend(ner)\n","        for word in words:\n","          if word not in stops:\n","            # words.append(w)\n","            top10[word]+=1\n","        words = [w for w in words if not w in stops]\n","    return (words)\n","\n","def essay_to_sentences(essay_v, remove_stopwords):\n","    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n","    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n","    raw_sentences = tokenizer.tokenize(essay_v.strip())\n","    sentences = []\n","    for raw_sentence in raw_sentences:\n","        if len(raw_sentence) > 0:\n","            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n","    return sentences\n","\n","def makeFeatureVec(words, model, num_features):\n","    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n","    featureVec = np.zeros((num_features,),dtype=\"float32\")\n","    num_words = 0.\n","    index2word_set = set(model.wv.index2word)\n","    for word in words:\n","        if word in index2word_set:\n","            num_words += 1\n","            featureVec = np.add(featureVec,model[word])\n","    featureVec = np.divide(featureVec,num_words)\n","    return featureVec\n","\n","def getAvgFeatureVecs(essays, model, num_features):\n","    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n","    counter = 0\n","    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n","    for essay in essays:\n","        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n","        counter = counter + 1\n","    return essayFeatureVecs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNx1fxinG_4h"},"source":["Below we declare the model. here the model is of older version. for running the most recent version please refer to readme, which inputs the model_type as well in terms of hyperparameter."]},{"cell_type":"code","metadata":{"id":"w8pjFmyC8V6k"},"source":["from keras.layers import Embedding, Input, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional, Conv2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n","from keras.models import Sequential,Model, load_model, model_from_config\n","import keras.backend as K\n","\n","def get_model(Hidden_dim1=400, Hidden_dim2=128, return_sequences = True, dropout=0.5, recurrent_dropout=0.4, input_size=768, activation='relu', bidirectional = False):\n","    \"\"\"Define the model.\"\"\"\n","    model = Sequential()\n","    if bidirectional:\n","        model.add(Bidirectional(LSTM(Hidden_dim1,return_sequences=return_sequences , dropout=0.4, recurrent_dropout=recurrent_dropout), input_shape=[1, input_size]))\n","        model.add(Bidirectional(LSTM(Hidden_dim2, recurrent_dropout=recurrent_dropout)))\n","    else:\n","        model.add(LSTM(Hidden_dim1, dropout=0.4, recurrent_dropout=recurrent_dropout, input_shape=[1, input_size], return_sequences=return_sequences))\n","        model.add(LSTM(Hidden_dim2, recurrent_dropout=recurrent_dropout))\n","    model.add(Dropout(dropout))\n","    model.add(Dense(1, activation=activation))\n","\n","    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n","    model.summary()\n","    return model\n","\n","def get_model_CNN(Hidden_dim1=400, Hidden_dim2=128, return_sequences = True, dropout=0.5, recurrent_dropout=0.4, input_size=768,output_dims=10380, activation='relu', bidirectional = False):\n","    \"\"\"Define the model.\"\"\"\n","    inputs = Input(shape=(768,1))\n","    x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(inputs)\n","    #Cuts the size of the output in half, maxing over every 2 inputs\n","    x = MaxPooling1D(pool_size=2)(x)\n","    x = Conv1D(128, 3, strides=1, padding='same', activation='relu')(x)\n","    x = GlobalMaxPooling1D()(x)\n","    outputs = Dense(output_dims, activation='relu')(x)\n","    model = Model(inputs=inputs, outputs=outputs, name='CNN')\n","    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gW9U6fU5HTBW"},"source":["Below we will run the model for all sets using BERT"]},{"cell_type":"code","metadata":{"id":"T1Aue2g3-ykA","outputId":"c2aa7bfb-0a1e-469f-83a5-8656a712e47f","colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["e25562d03a5345c8883776acc3242aa6","c2b185a36f254a1dbfd8723c96cd5d84","f3ad65eeb8f64a7bad6e4f8b21e34d46","3e7f6f57a40841ed9049a322179055e2","69f479beee014b258d0c5f2abaa6d559","4d98f9e411d04846b15e260c2a3b04ab","d6cbfa7f55ae453087f888101cfac940","ba7ea2d64c65475a939a60dbb895b79b","9b574ac044e6488a8b7501cec58882ea","f57bfd085ac14b37872747e33b0df5cd","8e2649de05e14951a6539954abb4b2c0","71e007137c1d47ac90ec89ab01204b45","e4a889e110a6491c8a48b7e2ae9266f6","71d034de7baf49119ce0c17d2dc3171f","f2f397cf81e443839cf3ff23f33cdb7e","b34a6402b283464c9a1bb697cc108db4","e2b1adb0bdf349efaa799f8730a30b07","8bac3db7a5ff4e3b94017bc402162b0b","8cc03c8fdac043a08cea7b1c8f3fe36e","4c74c91e49f64ba39097bbbd4402626a","98a56241dc6b4be5b329bab594bb4c05","232555988dba49a0b0b702a7a3fbfa0e","b508f3e0a4984eabaa5ce842780db8b4","ec5d0ec1fdc84096bc1d2a5a0650eed8","3c56a77571d14d2496a1372869f3454d","2941e2c504de49ac9b0d310e3f3eac15","88af7c96a17c4447995dd13497641ffc","1dcb18f6b0f54b7e8db3618e9c78b8b8","2aaf62a0c0e6401da6780d90952894e4","472607207fba404b8587202aa0f46d8b","3b0cc35a13da4253a0efcc5d280dedfb","68d02eb8cb534ceead54d30f3190db94","eef761cf4f1f495d8e17cfee8ad8ab20","1738fdd64304495caf6080f9f1944a34","99fe98ba8a664c5498f05e25dd91a63d","973169ecec7c42089dd34c4a1d765ee6","4fa9e498da364ef28c58bb3920a4bde8","6c45bd0d45024ec2a70b5ffb0b0c5bc4","f9dcd293c1f7426392d3f3e2783ad702","b7db8c296ebb4d159c65c13808fe0642","1daad78e0b614a309060ea63c500f09f","6b73619801fe449785becd40a7db2b51","1d2dd4fc11a84c009c8327fbe1dc47ef","9e763dce91d6464e9db9e556aad5632b"]}},"source":["## Sets experiment BERT\n","import time\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')\n","set_count = 1\n","all_sets_score = []\n","for s in sets:\n","  print(\"\\n--------SET {}--------\\n\".format(set_count))\n","  X = s\n","  y = s['domain1_score']\n","  cv = KFold(n_splits=5, shuffle=True)\n","  cv_data = cv.split(X)\n","  results = []\n","  prediction_list = []\n","  fold_count =1\n","  cuda = torch.device('cuda')\n","  # For DistilBERT:\n","  model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n","  ## Want BERT instead of distilBERT? Uncomment the following line:\n","  ##model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n","  # Load pretrained model/tokenizer\n","  tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","  model = model_class.from_pretrained(pretrained_weights)\n","  with torch.cuda.device(cuda):\n","    for traincv, testcv in cv_data:\n","      torch.cuda.empty_cache()\n","      print(\"\\n--------Fold {}--------\\n\".format(fold_count))\n","      # get the train and test from the dataset.\n","      X_train, X_test, y_train, y_test = X.iloc[traincv], X.iloc[testcv], y.iloc[traincv], y.iloc[testcv]\n","      train_essays = X_train['essay']\n","      #print(\"y_train\",y_train)\n","      test_essays = X_test['essay']\n","      # model = model.cuda()\n","      #y_train = torch.tensor(y_train,dtype=torch.long)\n","      sentences = []\n","      tokenize_sentences = []\n","      train_bert_embeddings = []\n","      #bert_embedding = BertEmbedding()\n","      # for essay in train_essays:\n","      #   # get all the sentences from the essay\n","      #   sentences += essay_to_sentences(essay, remove_stopwords = True)\n","      # sentences = pd.Series(sentences)\n","      # print(train_essays)\n","      tokenized_train = train_essays.apply((lambda x: tokenizer.encode(x, add_special_tokens=True ,max_length=200)))\n","      tokenized_test = test_essays.apply((lambda x: tokenizer.encode(x, add_special_tokens=True ,max_length=200)))\n","\n","\n","      ## train\n","      max_len = 0\n","      for i in tokenized_train.values:\n","        if len(i) > max_len:\n","          max_len = len(i)\n","      padded_train = np.array([i + [0]*(max_len-len(i)) for i in tokenized_train.values])\n","\n","      attention_mask_train = np.where(padded_train != 0, 1, 0)\n","\n","\n","\n","      train_input_ids = torch.tensor(padded_train)\n","      train_attention_mask = torch.tensor(attention_mask_train)\n","      with torch.no_grad():\n","        last_hidden_states_train = model(train_input_ids, attention_mask=train_attention_mask)\n","\n","\n","      train_features = last_hidden_states_train[0][:,0,:].numpy()\n","\n","\n","      ## test\n","      max_len = 0\n","      for i in tokenized_test.values:\n","        if len(i) > max_len:\n","          max_len = len(i)\n","      padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])\n","      attention_mask_test = np.where(padded_test != 0, 1, 0)\n","      test_input_ids = torch.tensor(padded_test)\n","      test_attention_mask = torch.tensor(attention_mask_test)\n","\n","      with torch.no_grad():\n","        last_hidden_states_test = model(test_input_ids, attention_mask=test_attention_mask)\n","\n","      test_features = last_hidden_states_test[0][:,0,:].numpy()\n","\n","\n","\n","\n","      train_x,train_y = train_features.shape\n","      test_x,test_y = test_features.shape\n","\n","      trainDataVectors = np.reshape(train_features,(train_x,1,train_y))\n","      testDataVectors = np.reshape(test_features,(test_x,1,test_y))\n","\n","      lstm_model = get_model(bidirectional=False)\n","      lstm_model.fit(trainDataVectors, y_train, batch_size=128, epochs=70)\n","      y_pred = lstm_model.predict(testDataVectors)\n","\n","      y_pred = np.around(y_pred)\n","      #y_pred.dropna()\n","      np.nan_to_num(y_pred)\n","      # evaluate the model\n","      result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n","      print(\"Kappa Score: {}\".format(result))\n","      results.append(result)\n","      fold_count +=1\n","      import tensorflow as tf\n","      tf.keras.backend.clear_session()\n","\n","\n","\n","  all_sets_score.append(results)\n","  print(\"Average kappa score value is : {}\".format(np.mean(np.asarray(results))))\n","  set_count+=1\n","    # print(features.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--------SET 1--------\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25562d03a5345c8883776acc3242aa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71e007137c1d47ac90ec89ab01204b45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b508f3e0a4984eabaa5ce842780db8b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1738fdd64304495caf6080f9f1944a34"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["\n","--------Fold 1--------\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"vaVJpB5JHkGf"},"source":["Below we will run for whole dataset using BERT but using CNN, which didnt performed so well."]},{"cell_type":"code","metadata":{"id":"cW2lZ-R38Xot"},"source":[" # For whole dataset\n","import time\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')\n","cv = KFold(n_splits=5, shuffle=True)\n","# X = set8\n","# y = set8['domain1_score']\n","X= data\n","y = data['domain1_score']\n","cv_data = cv.split(X)\n","results = []\n","prediction_list = []\n","fold_count =1\n","# use_cuda = True\n","# if use_cuda and torch.cuda.is_available():\n","#   torch.cuda()\n","# Hyperpaprameters for LSTM\n","Hidden_dim1=300\n","Hidden_dim2=100\n","return_sequences = True\n","dropout=0.5\n","recurrent_dropout=0.4\n","input_size=768\n","activation='relu'\n","bidirectional = True\n","batch_size = 64\n","epoch = 100\n","#####\n","cuda = torch.device('cuda')\n","# For DistilBERT:\n","model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n","## Want BERT instead of distilBERT? Uncomment the following line:\n","##model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n","# Load pretrained model/tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)\n","with torch.cuda.device(cuda):\n","  for traincv, testcv in cv_data:\n","    torch.cuda.empty_cache()\n","    print(\"\\n--------Fold {}--------\\n\".format(fold_count))\n","    # get the train and test from the dataset.\n","    X_train, X_test, y_train, y_test = X.iloc[traincv], X.iloc[testcv], y.iloc[traincv], y.iloc[testcv]\n","    train_essays = X_train['essay']\n","    #print(\"y_train\",y_train)\n","    test_essays = X_test['essay']\n","    # model = model.cuda()\n","    #y_train = torch.tensor(y_train,dtype=torch.long)\n","    sentences = []\n","    tokenize_sentences = []\n","    train_bert_embeddings = []\n","    #bert_embedding = BertEmbedding()\n","    # for essay in train_essays:\n","    #   # get all the sentences from the essay\n","    #   sentences += essay_to_sentences(essay, remove_stopwords = True)\n","    # sentences = pd.Series(sentences)\n","    # print(train_essays)\n","    tokenized_train = train_essays.apply((lambda x: tokenizer.encode(x, add_special_tokens=True ,max_length=55)))\n","    tokenized_test = test_essays.apply((lambda x: tokenizer.encode(x, add_special_tokens=True ,max_length=55)))\n","\n","\n","    ## train\n","    max_len = 0\n","    for i in tokenized_train.values:\n","      if len(i) > max_len:\n","        max_len = len(i)\n","    padded_train = np.array([i + [0]*(max_len-len(i)) for i in tokenized_train.values])\n","\n","    attention_mask_train = np.where(padded_train != 0, 1, 0)\n","\n","\n","\n","    train_input_ids = torch.tensor(padded_train)\n","    train_attention_mask = torch.tensor(attention_mask_train)\n","    with torch.no_grad():\n","      last_hidden_states_train = model(train_input_ids, attention_mask=train_attention_mask)\n","\n","\n","    train_features = last_hidden_states_train[0][:,0,:].numpy()\n","\n","\n","    ## test\n","    max_len = 0\n","    for i in tokenized_test.values:\n","      if len(i) > max_len:\n","        max_len = len(i)\n","    padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])\n","    attention_mask_test = np.where(padded_test != 0, 1, 0)\n","    test_input_ids = torch.tensor(padded_test)\n","    test_attention_mask = torch.tensor(attention_mask_test)\n","\n","    with torch.no_grad():\n","      last_hidden_states_test = model(test_input_ids, attention_mask=test_attention_mask)\n","\n","    test_features = last_hidden_states_test[0][:,0,:].numpy()\n","    train_x,train_y = train_features.shape\n","    test_x,test_y = test_features.shape\n","    trainDataVectors = np.reshape(train_features,(train_x,1,train_y))\n","    testDataVectors = np.reshape(test_features,(test_x,1,test_y))\n","    # print(trainDataVectors)\n","    # print(testDataVectors)\n","    # trainDataVectors = np.reshape(train_features,(train_x,train_y,1))\n","    # testDataVectors = np.reshape(test_features,(test_x,test_y,1))\n","    trainDataVectors = np.reshape(train_features,(train_x,1, train_y))\n","    testDataVectors = np.reshape(test_features,(test_x,1, test_y))\n","    # lstm_model = get_model_CNN(bidirectional=False, output_dims = 1)\n","    lstm_model = get_model(Hidden_dim1=Hidden_dim1, Hidden_dim2=Hidden_dim2, return_sequences=return_sequences,\n","                            dropout=dropout, recurrent_dropout=recurrent_dropout, input_size=input_size,\n","                            activation=activation, bidirectional=bidirectional)\n","    history = lstm_model.fit(trainDataVectors, y_train, batch_size=batch_size, epochs=epoch)\n","    plot_accuracy_curve(history)\n","    y_pred = lstm_model.predict(testDataVectors)\n","    y_pred = np.around(y_pred)\n","    #y_pred.dropna()\n","    np.nan_to_num(y_pred)\n","    # evaluate the model\n","    print(y_pred)\n","    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n","    print(\"Kappa Score: {}\".format(result))\n","    results.append(result)\n","    fold_count +=1\n","    import tensorflow as tf\n","    tf.keras.backend.clear_session()\n","print(\"Average kappa score value is : {}\".format(np.mean(np.asarray(results))))\n","  # print(features.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y2ypVnoH1m8D"},"source":["import tensorflow as tf\n","tf.keras.backend.clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Vfp2iOuOxGF"},"source":["trainDataVectors = np.reshape(train_features,(train_x,train_y,1))\n","testDataVectors = np.reshape(test_features,(test_x,test_y,1))\n","print(y_train.shape)\n","print(trainDataVectors.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqIKQXYaLS_r"},"source":["# x = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n","def plot_qwk_scores_all_sets():\n","  fig = plt.figure()\n","  ax = plt.subplot(111)\n","  x = [1,2,3,4,5]\n","  ax.plot(x, set1 , label='set1')\n","  ax.plot(x, set2, label='set2')\n","  ax.plot(x, set3, label='set3')\n","  ax.plot(x, set4, label='set4')\n","  ax.plot(x, set5, label='set5')\n","  ax.plot(x, set6, label='set6')\n","  ax.plot(x, set7, label='set7')\n","  ax.plot(x, set8, label='set8')\n","  plt.title('Set wise QWK using BERT for individual sets')\n","  ax.legend()\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7iiwRVaHvbB"},"source":["Buildind word2vec model method to render the text and convert to word2vec feature vector."]},{"cell_type":"code","metadata":{"id":"cRoovMdOLo7L"},"source":["def build_word2vec(train_sentences, num_workers, num_features, min_word_count, context,\n","                     downsampling):\n","    model = Word2Vec(workers=num_workers, size=num_features, min_count=min_word_count, window=context,\n","                     sample=downsampling)\n","    # saving the word2vec model\n","    # model.wv.save_word2vec_format('word2vec_'+ str(fold_count) +'.bin', binary=True)\n","    cores = multiprocessing.cpu_count()\n","    print(\"\\n {} cores using\".format(cores))\n","    start_time = time.time()\n","    model.build_vocab(train_sentences, progress_per=10000)\n","    print('Time to build vocab using word2vec: {} sec'.format(time.time() - start_time))\n","    start_time = time.time()\n","    model.train(train_sentences, total_examples=model.corpus_count, epochs=epochs, report_delay=1)\n","    print('Time to train the word2vec model: {} mins'.format(time.time() - start_time))\n","    model.init_sims(replace=True)\n","    sorted_dic = sorted(top10.items(), key=lambda k: k[1], reverse=True)\n","    return model,sorted_dic"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ylv12NWaH3hq"},"source":["Below method will run on individual sets using word2vec"]},{"cell_type":"code","metadata":{"id":"zOi-yY2JkzPV","cellView":"both"},"source":["# Individual sets\n","import time\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')\n","set_count = 1\n","all_sets_score = []\n","# Hyperparameters for word2vec\n","num_features = 400\n","min_word_count = 40\n","num_workers = 4\n","context = 10\n","downsampling = 1e-3\n","epochs = 30\n","\n","# Hyperpaprameters for LSTM\n","Hidden_dim1=300\n","Hidden_dim2=100\n","return_sequences = True\n","dropout=0.5\n","recurrent_dropout=0.4\n","input_size=400\n","activation='relu'\n","bidirectional = True\n","batch_size = 64\n","epoch = 70\n","#####\n","####\n","import tensorflow as tf\n","tf.keras.backend.clear_session()\n","\n","for s in sets:\n","  print(\"\\n--------SET {}--------\\n\".format(set_count))\n","  set_count +=1\n","  X = s\n","  y = s['domain1_score']\n","  cv = KFold(n_splits=5, shuffle=True)\n","  #X, y = prepare_data(dataset_path=dataset_path)\n","  cv_data = cv.split(X)\n","  results = []\n","  prediction_list = []\n","  fold_count =1\n","  # hyperparameters for word2vec\n","  most_common_words= []\n","  print(X.shape)\n","  print(y.shape)\n","  for traincv, testcv in cv_data:\n","      print(\"\\n--------Fold {}--------\\n\".format(fold_count))\n","      # get the train and test from the dataset.\n","      X_train, X_test, y_train, y_test = X.iloc[traincv], X.iloc[testcv], y.iloc[traincv], y.iloc[testcv]\n","      train_essays = X_train['essay']\n","      #print(\"y_train\",y_train)\n","      test_essays = X_test['essay']\n","      #y_train = torch.tensor(y_train,dtype=torch.long)\n","      train_sentences = []\n","      # print(\"train_essay \",train_essays.shape)\n","      #print(X_train.shape,y_train.shape)\n","      for essay in train_essays:\n","          # get all the sentences from the essay\n","          train_sentences.append(essay_to_wordlist(essay, remove_stopwords = True))\n","\n","      # word2vec embedding\n","      print(\"Converting sentences to word2vec model\")\n","      model,_ = build_word2vec(train_sentences, num_workers, num_features, min_word_count, context,\n","                    downsampling)\n","      top10 = collections.defaultdict(int)\n","\n","      # print(\"train_sentencesshap\",len(train_sentences))\n","      trainDataVecs = np.array(getAvgFeatureVecs(train_sentences, model, num_features))\n","      test_sentences = []\n","      for essay_v in test_essays:\n","          test_sentences.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n","      testDataVecs = np.array(getAvgFeatureVecs(test_sentences, model, num_features))\n","      trainDataVectors = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n","      testDataVectors = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n","      lstm_model = get_model_lstm(Hidden_dim1=Hidden_dim1, Hidden_dim2=Hidden_dim2, return_sequences=return_sequences,\n","                              dropout=dropout, recurrent_dropout=recurrent_dropout, input_size=input_size,\n","                              activation=activation, bidirectional=bidirectional)\n","      # print(trainDataVectors.shape)\n","      # print(y_train.shape)\n","      history = lstm_model.fit(trainDataVectors, y_train, batch_size=batch_size, epochs=epoch)\n","      plot_accuracy_curve(history)\n","      y_pred = lstm_model.predict(testDataVectors)\n","      y_pred = np.around(y_pred)\n","      np.nan_to_num(y_pred)\n","      result = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n","      print(\"Kappa Score: {}\".format(result))\n","      results.append(result)\n","      fold_count += 1\n","\n","  print(\"Average kappa score value is : {}\".format(np.mean(np.asarray(results))))\n","  all_sets_score.append(results)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMShF5qOIBqo"},"source":["Below method is for running the model on whole dataset using the word2vec model."]},{"cell_type":"code","metadata":{"id":"5l3ZKmfVk16I"},"source":["# Whole Dataset Word2vec\n","X= data\n","y = data['domain1_score']\n","import time\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')\n","set_count = 1\n","all_sets_score = []\n","# Hyperparameters for word2vec\n","num_features = 400\n","min_word_count = 40\n","num_workers = 4\n","context = 10\n","downsampling = 1e-3\n","epochs = 30\n","\n","# Hyperpaprameters for LSTM\n","Hidden_dim1=300\n","Hidden_dim2=100\n","return_sequences = True\n","dropout=0.5\n","recurrent_dropout=0.4\n","input_size=400\n","activation='relu'\n","bidirectional = True\n","batch_size = 64\n","epoch = 70\n","#####\n","####\n","import tensorflow as tf\n","tf.keras.backend.clear_session()\n","cv = KFold(n_splits=5, shuffle=True)\n","#X, y = prepare_data(dataset_path=dataset_path)\n","cv_data = cv.split(X)\n","results = []\n","prediction_list = []\n","fold_count =1\n","# hyperparameters for word2vec\n","most_common_words= []\n","print(X.shape)\n","print(y.shape)\n","for traincv, testcv in cv_data:\n","    print(\"\\n--------Fold {}--------\\n\".format(fold_count))\n","    # get the train and test from the dataset.\n","    X_train, X_test, y_train, y_test = X.iloc[traincv], X.iloc[testcv], y.iloc[traincv], y.iloc[testcv]\n","    train_essays = X_train['essay']\n","    #print(\"y_train\",y_train)\n","    test_essays = X_test['essay']\n","    #y_train = torch.tensor(y_train,dtype=torch.long)\n","    train_sentences = []\n","    # print(\"train_essay \",train_essays.shape)\n","    #print(X_train.shape,y_train.shape)\n","    for essay in train_essays:\n","        # get all the sentences from the essay\n","        train_sentences.append(essay_to_wordlist(essay, remove_stopwords = True))\n","\n","    # word2vec embedding\n","    print(\"Converting sentences to word2vec model\")\n","    model,_ = build_word2vec(train_sentences, num_workers, num_features, min_word_count, context,\n","                  downsampling)\n","    top10 = collections.defaultdict(int)\n","\n","    # print(\"train_sentencesshap\",len(train_sentences))\n","    trainDataVecs = np.array(getAvgFeatureVecs(train_sentences, model, num_features))\n","    test_sentences = []\n","    for essay_v in test_essays:\n","        test_sentences.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n","    testDataVecs = np.array(getAvgFeatureVecs(test_sentences, model, num_features))\n","    trainDataVectors = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n","    testDataVectors = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n","    lstm_model = get_model_lstm(Hidden_dim1=Hidden_dim1, Hidden_dim2=Hidden_dim2, return_sequences=return_sequences,\n","                            dropout=dropout, recurrent_dropout=recurrent_dropout, input_size=input_size,\n","                            activation=activation, bidirectional=bidirectional)\n","    # print(trainDataVectors.shape)\n","    # print(y_train.shape)\n","    history = lstm_model.fit(trainDataVectors, y_train, batch_size=batch_size, epochs=epoch)\n","    plot_accuracy_curve(history)\n","    y_pred = lstm_model.predict(testDataVectors)\n","    y_pred = np.around(y_pred)\n","    np.nan_to_num(y_pred)\n","    result = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n","    print(\"Kappa Score: {}\".format(result))\n","    results.append(result)\n","    fold_count += 1\n","\n","print(\"Average kappa score value is : {}\".format(np.mean(np.asarray(results))))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vqFLucVADEps"},"source":[]}]}